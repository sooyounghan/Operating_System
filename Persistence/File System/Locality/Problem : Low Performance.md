-----
### 문제 : 낮은 성능
-----
1. 성능이 형편 없음
   - 성능은 처음부터 안 좋게 시작해서 시간이 지남에 따라 더 좋지 않아지며 나중에는 파일 시스템이 디스크의 전반적인 대역폭의 2%뿐 사용 못하는 결과를 보임
  
2. 구형 파일 시스템의 핵심 문제는 디스크를 마치 임의 접근 기억 장치(RAM)처럼 사용한다는 것
   - 데이터를 저장하는 매체가 디스크라는 사실을 무시하고 여러 곳에 데이터를 저장하므로 디스크 헤드를 이동하는데 오랜 시간이 소요
   - 예를 들어, 파일의 데이터 블럭이 대체로 아이노드에서 멀리 떨어져 있으므로 아이노드를 읽은 후 파일의 데이터 블럭에 접근하려면 디스크 헤드를 이동하는 데 많은 시간을 소요
   - 아이노드를 읽은 후 해당 데이터 블럭을 읽는 작업은 매우 흔하게 일어남

3. 더 안 좋은 것은 파일 시스템이 빈 공간을 효율적으로 관리하지 않으므로 결국에는 공간은 단편화(Fragement)됨
   - 빈 공간들이 디스크 전역에 흩어져 있으며, 새로운 블럭 할당 시 무조건 리스트에서 다음 빈 블럭을 할당
   - 그 결과 파일을 순차적으로 읽더라도 실제로는 디스크 전역을 오가며 블럭에 접근하므로 성능이 심각하게 나빠짐
   - 예를 들어 다음과 같은 데이터 블럭 영역을 생각 : 네 개의 파일(A, B, C, D)이 있으며 각 2개의 블럭의 크기를 가짐
<div align="center">
<img src="https://github.com/user-attachments/assets/664bd17d-c8db-4a4d-8d15-20d267492e12">
</div>

   - B와 D가 삭제되면 다음과 같은 상태
<div align="center">
<img src="https://github.com/user-attachments/assets/c45c34ed-bc47-4331-81dc-11054d8e09b6">
</div>

   - 비어있는 공간은 보는 바와 같이 네 개의 블럭이 연속된 청크가 아닌 두 블럭 크기로 단편화
   - 네 개의 블록으로 구성된 파일 E를 할당
<div align="center">
<img src="https://github.com/user-attachments/assets/29ff6c34-e7b5-466d-848d-71aec0a01e21">
</div>

   - E를 이루는 블럭들은 디스크 상에서 흩어져 있게 됨
   - E를 읽거나 쓸 경우, 디스크로부터 최대(순차) 성능을 얻을 수 없음
   - 먼저 E1와 E2를 읽고, 디스크 헤드를 이동시켜 E3과 E4를 읽어야 함
   - 이처럼 오래된 UNIX 파일 시스템에서 단편화는 흔하게 발생하며 성능에 악영향을 줌

4. 또한, 블럭 크기가 너무 작음 (512 Byte)
   - 입출력 단위가 너무 작으므로 디스크로부터 데이터를 전송하는 것은 원천적으로 매우 비효율적
   - 작은 크기의 블럭은 내부 단편화(Internal Fragmentation, 블럭 내 낭비)가 작은 장점이 있음
   - 그러나 디스크 헤드의 이동시간에 비해 데이터 블럭의 크기가 작으므로 입출력이 상대적으로 비효율적이 됨

   
