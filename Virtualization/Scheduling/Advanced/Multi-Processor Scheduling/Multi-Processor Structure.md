-----
### 멀티프로세서 구조
-----
1. 단일 CPU와 멀티 CPU 하드웨어의 근본적 차이 : 다수의 프로세서 간의 데이터 공유, 하드웨어의 캐시 사용 방식에서 근본적 차이 발생
2. 단일 CPU 시스템에는 하드웨어 캐시 계층이 존재
<div align="center">
<img src="https://github.com/user-attachments/assets/9c850cad-fd20-45e2-8074-9ad6a96a094b">
</div>

   - 이 캐시는 프로그램을 빠르게 실행하기 위해 존재
   - 캐시는 메인 메모리에서 자주 사용되는 데이터 복사본을 저장하는 작고 빠른 메모리
   - 메인 메모리는 모든 데이터를 저장하지만 느리므로, 자주 접근되는 데이터를 캐시에 임시로 가져다 둠으로써 시스템은 크고 느린 메모리를 빠른 메모리처럼 보이게 함
   - 예를 들어, load 명령어를 수행하는 프로그램과 하나의 CPU만 있는 간단한 시스템을 생각
     + 데이터가 메인 메모리에 존재하므로 데이터를 가져오는데 오랜 시간이 소모 (수십 ~ 수백 나노초)
     + 데이터가 다시 사용될 것으로 예상되는 프로세서는 읽은 데이터 복사본을 CPU 캐시에 저장
     + 프로그램이 나중에 다시 같은 데이터를 가져오려고 한다면, CPU는 우선 해당 데이터가 캐시에 존재하는지 검사하고, 캐시에 존재하기 때문에 데이터는 훨씬 빨리 접근 (수 나노초) 프로그램은 빨리 실행
    
3. 캐시는 지역성(Locality)에 기반
   - 지역성에는 시간 지역성(Temporal Locality)과 공간 지역성(Spatial Locality)의 두 종류가 존재
   - 시간 지역성의 기본 아이디어 : 데이터가 한 번 접근되면 가까운 미래에 다시 접근되기 쉬움 (예) 루프에서 여러 번 반복해서 접근되는 변수 또는 명령어)
   - 공간 지역성의 기본 아이디어 : 프로그램이 주소 x의 데이터를 접근하면 x 주변의 데이터가 접근되기 쉬움 (예) 하드웨어 시스템은 캐시에 어떤 데이터를 저장할지 비교적 정확하게 추측할 수 있고, 캐시는 잘 작동)

4. 하나의 시스템에 여러 프로세서가 존재하고 하나의 공유 메인 메모리가 있을 때
<div align="center">
<img src="https://github.com/user-attachments/assets/0ee40e98-e4cd-472a-a4d8-1ebe92921af5">
</div>

   - 멀티프로세서 시스템에서 캐시를 사용하는 것은 헐씬 복잡
   - 예를 들어, CPU 1에서 실행 중인 프로그램이 주소 A를 (D 값) 읽는다고 가정
   - 데이터가 CPU 1 캐시에 존재하지 않으므로 시스템은 메인 메모리로부터 데이터를 가져오고 값 D를 얻어옴
   - 그런 후 프로그램은 주소 A의 값을 변경 (변경은 캐시에 존재하는 값만 D'으로 갱신)
   - 메모리에 데이터를 쓰는 것은 시간이 오래 걸리므로, 메인 메모리에 기록하는 것은 보통 나중에 실시
   - 운영체제가 프로그램 실행을 중단하고 CPU 2로 이동하기로 결정했다고 가정
     + 프로그램은 주소 A의 값을 다시 읽는데, CPU 2 캐시에는 그런 데이터가 존재하지 않고 시스템 메인 메모리에서 데이터를 가져오는데, D'가 아닌 이전 값인 D 값을 가져옴
   - 이런 문제를 '캐시 일관성 문제(Cache Coherence)' 문제라고 부름

5. 기본적인 해결책 : 하드웨어에 의해 제공
   - 하드웨어는 메모리 주소를 계속 감시하고, 항상 제대로된 상황만 발생하도록 시스템 관리
   - 특히, 여러 개 프로세스들이 하나의 메모리에 갱신할 때는 항상 공유되도록 함
   - 버스 기반 시스템에서는 버스 스누핑(Bus Snooping)이라는 오래된 기법 사용
   - 캐시는 자신과 메모리를 연결하는 버스의 통신 상황을 계속 모니터링하며, 캐시 데이터에 대한 변경이 발생하면 자신의 복사본을 무효화시키거나(자신의 캐시에서 삭제) 갱신(새로운 값을 캐시에 기록)
   - 나중 쓰기(Write-Back) 캐시는 메인 메모리에 쓰기 연산이 지연되므로 캐시 일관성 유지 문제를 훨씬 복잡하게 만듬

-----
### 동기화
-----
1. CPU들이 동일한 데이터 또는 구조체에 접근할 때(특히, 갱신), 올바른 연산 결과를 보장하기 위해 락과 같은 상호 배제를 보장하는 동기화 기법이 많이 사용
2. 락-프리(Lock-Free) 데이터 구조 등의 다른 방식은 특별한 경우에만 사용
   - 예를 들어, 여러 CPU가 동시에 사용하는 공유 큐가 있다고 가정
   - 캐시의 일관성을 보장하는 프로토콜이 존재한다 하더라도 락 없이는 항목의 추가나 삭제가 제대로 동작하지 않을 것
   - 구조체를 원자적 갱신하기 위해서는 락 필요
3. 연결 리스트에서 원소 하나를 삭제하는 코드
<div align="center">
<img src="https://github.com/user-attachments/assets/55c23379-514f-40b7-9a14-5d5441d0646e">
</div>

   - 두 CPU의 쓰레드가 동시에 이 루틴에 진입한다고 가정
   - 쓰레드 1이 첫 번째 행을 실행하면 head의 현재 값을 temp에 저장
   - 그런 후 쓰레드 2가 첫 번째 행을 실행하면 역시 head의 같은 값을 tmp에 저장하며, tmp는 스택에 할당
   - 각 쓰레드는 자신만의 스택을 가지고 있으며, 각 쓰레드는 동일한 헤드 원소를 제거하려고 함
   - 제대로 된 상황이라면 각 쓰레드는 리스트의 첫 번째 원소를 한 번씩 제거해야 하는데, 4행의 헤드 원소를 두 번삭제 같은 데이터 값을 두 번 반환 하는 등의 문제 야기
   - 해결책은 락(Lock)을 이용해 올바르게 동작하는 것
     + 간단한 mutex를 할당하고(예) pthread_mutext_t m) 루틴의 시작에 lock(&m), 마지막에 unlock(&m)을 추가하면 문제 해결 가능 (하지만 성능적으로 문제가 발생하며, CPU 개수가 증가할수록 동기화된 자료 구조에 접근하는 연산은 매우 느려짐)

-----
### 캐시 친화성 (Cache Affinity)
-----
1. CPU에서 실행될 때 프로세스는 해당 CPU 캐시와 TLB에 상당한 양의 상태 정보를 올려 놓게 됨
2. 다음 번에 프로세스가 실행될 때 동일한 CPU에서 실행되는 것이 유리한데, 해당 CPU 캐시에 일부 정보가 이미 존재하므로 더 빨리실행될 것
3. 반면 프로세스가 매번 다른 CPU에서 실행되면 실행할 때마다 필요 정보를 캐시에 다시 탑재해야하므로 프로세스 성능은 더욱 나빠질 것
4. 하드웨이 캐시 일관성 프로토콜 덕분에 다른 CPU에서 실행되더라도 프로그램이 제대로 실행될 것이지만, 멀티프로세스 스케줄러는 스케줄링 결정을 내릴 때 캐시 친화성을 고려해야 함
5. 즉, 가능한 한 프로세스를 동일한 CPU에서 실행하려고 노력하는 방향으로 결정 필요
